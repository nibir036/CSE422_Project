# -*- coding: utf-8 -*-
"""422_Project_2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mxzzVDOGltcikBAk9lFFGRKDm4xYFAIB
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Find the dataset at https://www.kaggle.com/datasets/tunguz/used-car-auction-prices

df = pd.read_csv('/content/drive/MyDrive/CSE422 Lab/Project/car_prices.csv', on_bad_lines='skip')

"""###Exploratory Data Analysis"""

df.head(20)

df = df.head(70000)
df.size

df.info()

df.isnull().sum()

df.shape

df.describe()

df.nunique()

"""###Data Visualization"""

selling_price_bins = [0, 5000, 10000, 15000, 20000, 25000, 30000]
selling_price_labels = ["0-5k", "5k-10k", "10k-15k", "15k-20k", "20k-25k", "25k-30k"]

condition_bins = [0, 1, 2, 3, 4, 5]
condition_labels = ["0-1", "1-2", "2-3", "3-4", "4-5"]

df['sellingprice_range'] = pd.cut(df['sellingprice'], bins=selling_price_bins, labels=selling_price_labels, right=False)
df['condition_range'] = pd.cut(df['condition'], bins=condition_bins, labels=condition_labels, right=False)

# Plotting Selling Price Range Histogram
plt.figure(figsize=(12, 6))
sns.countplot(x='sellingprice_range', data=df, palette='Blues', order=selling_price_labels)
plt.title('Distribution of Selling Price Ranges', fontsize=16)
plt.xlabel('Selling Price Range', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y', alpha=0.3)
plt.show()

# Plotting Condition Range Histogram
plt.figure(figsize=(12, 6))
sns.countplot(x='condition_range', data=df, palette='Greens', order=condition_labels)
plt.title('Distribution of Condition Ranges', fontsize=16)
plt.xlabel('Condition Range', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y', alpha=0.3)
plt.show()

import seaborn as sns

# Pair plot with seaborn
sns.pairplot(df, diag_kind="kde")

# Plotting Selling Price vs. Condition as a Line Graph

plt.figure(figsize=(10, 6))
sns.lineplot(x='condition', y='sellingprice', data=df, color='red', marker='o', linewidth=2, label='Selling Price')

plt.title('Selling Price vs. Condition', fontsize=16)
plt.xlabel('Condition', fontsize=12)
plt.ylabel('Selling Price', fontsize=12)
plt.grid(alpha=0.3)
plt.legend()
plt.show()

# Plot to visualize Most Popular Make and Model Combination

df['make_model'] = df['make'] + " " + df['model']

make_model_counts = df['make_model'].value_counts().reset_index()
make_model_counts.columns = ['make_model', 'count']

plt.figure(figsize=(12, 6))
sns.barplot(x='count', y='make_model', data=make_model_counts.head(15), palette='viridis')
plt.title('Top 15 Most Popular Make and Model Combinations', fontsize=16)
plt.xlabel('Count', fontsize=12)
plt.ylabel('Make and Model', fontsize=12)
plt.grid(axis='x', alpha=0.3)
plt.show()

!pip install squarify

# Treemap plot for top 10 make-model combinations

import squarify

plt.figure(figsize=(12, 6))
squarify.plot(
    sizes=make_model_counts['count'].head(15),
    label=make_model_counts['make_model'].head(15),
    alpha=0.8,
    color=plt.cm.viridis(range(15))
)
plt.title('Treemap of Top 15 Make and Model Popularity', fontsize=16)
plt.axis('off')
plt.show()

# Plot to visualize Condition Distribution

condition_bins = [0, 1, 2, 3, 4, 5]
condition_labels = ["0-1", "1-2", "2-3", "3-4", "4-5"]
df['condition_range'] = pd.cut(df['condition'], bins=condition_bins, labels=condition_labels, right=False)

condition_counts = df['condition_range'].value_counts()

plt.figure(figsize=(8, 8))
condition_counts.plot(kind='pie', autopct='%1.1f%%', colors=plt.cm.Paired.colors, startangle=90)
plt.title('Condition Distribution', fontsize=16)
plt.ylabel('')
plt.show()

# Plot to explore Correlation Heatmap of Numerical Features

numerical_features = ['odometer', 'condition', 'mmr', 'sellingprice']
corr_matrix = df[numerical_features].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='Purples', fmt='.2f', linewidths=0.5, cbar=True)
plt.title('Correlation Heatmap of Numerical Features', fontsize=16)
plt.show()

# Hexbin Plot to visualize Distribution of Odometer vs Selling Price

plt.figure(figsize=(10, 6))

plt.hexbin(df['odometer'], df['sellingprice'], gridsize=50, cmap='Greens', reduce_C_function=np.mean)

plt.colorbar(label='Average Selling Price')
plt.title('Odometer vs Selling Price (Hexbin Plot)', fontsize=16)
plt.xlabel('Odometer Reading (miles)', fontsize=12)
plt.ylabel('Selling Price ($)', fontsize=12)
plt.show()

# Box plot for 'odometer' column
plt.figure(figsize=(10, 6))
sns.boxplot(x=df['odometer'])
plt.title('Box plot for Odometer')
plt.show()

# Box plot for 'sellingprice' column
plt.figure(figsize=(10, 6))
sns.boxplot(x=df['sellingprice'])
plt.title('Box plot for Selling Price')
plt.show()

"""###Data Preprocessing"""

missing_percentage = (df.isnull().sum() / len(df)) * 100
print(missing_percentage)

columns_with_missing = df.columns[df.isnull().any()]
print(columns_with_missing)

missing_rows = df[df['make'].isnull()]
missing_rows.shape

df = df.dropna(subset=['make', 'model'], how='all')

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

for col in numerical_columns:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].mean(), inplace=True)

print(df.isnull().sum())

df['model'].fillna('Unknown', inplace=True)
df['trim'].fillna('Unknown', inplace=True)
df['body'].fillna('Unknown', inplace=True)
df['transmission'].fillna('Unknown', inplace=True)

df['color'].fillna(df['color'].mode()[0], inplace=True)
df['interior'].fillna(df['interior'].mode()[0], inplace=True)

missing_values = df.isnull().sum()
print(missing_values)

duplicates = df.duplicated()
print(f"Number of duplicate rows: {duplicates.sum()}")

"""###Feature Engineering"""

from scipy.stats import zscore

# Calculate Z-scores for the numerical columns
df['odometer_zscore'] = zscore(df['odometer'])
df['sellingprice_zscore'] = zscore(df['sellingprice'])

# Check for outliers (Z-score greater than 3 or less than -3)
odometer_outliers = df[df['odometer_zscore'].abs() > 3]
sellingprice_outliers = df[df['sellingprice_zscore'].abs() > 3]

print(f"Odometer outliers: {odometer_outliers.shape[0]}")
print(f"Selling price outliers: {sellingprice_outliers.shape[0]}")

# Remove rows where odometer or sellingprice is an outlier (Z-score > 3 or < -3)

df = df[(df['odometer_zscore'].abs() <= 3) & (df['sellingprice_zscore'].abs() <= 3)]

df.info()

df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce', utc=True)
df['year'] = df['saledate'].dt.year.astype(int)
df.head(2)

df = df.drop(columns=['vin','saledate','odometer_zscore','sellingprice_zscore','sellingprice_range','condition_range','make_model'])
df.head(1)

df.info()

"""###One-Hot Encoding // Label Encoding"""

print(df.dtypes)

categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    print(f"{col}: {df[col].nunique()} unique values")

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

high_cardinality_columns = ['make', 'model', 'trim','body','seller']
for col in high_cardinality_columns:
    df[col] = le.fit_transform(df[col].fillna('Unknown'))

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(drop='first')

encoded = encoder.fit_transform(df[['transmission', 'state', 'color', 'interior']]).toarray()

encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['transmission', 'state', 'color', 'interior']))

df = pd.concat([df.drop(['transmission', 'state', 'color', 'interior'], axis=1), encoded_df], axis=1)

df.head()

"""###Train-Test Split"""

# Train Test And Split

from sklearn.model_selection import train_test_split

X = df.drop(columns=['sellingprice'])
y = df['sellingprice']

# Before fitting the model
# Impute NaN in 'sellingprice' with the mean
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
y = imputer.fit_transform(y.values.reshape(-1, 1))
y = y.ravel()  # Convert back to 1D array

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""###Model Training

*   Random Forest


"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

rf_model.fit(X_train, y_train)

"""

*   Evaluation of Random Forest

"""

y_pred_rf = rf_model.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = mse_rf ** 0.5
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest MAE: {mae_rf:.2f}")
print(f"Random Forest MSE: {mse_rf:.2f}")
print(f"Random Forest RMSE: {rmse_rf:.2f}")
print(f"Random Forest R²: {r2_rf:.2f}")

print("Test set score: {:.2f}".format(rf_model.score(X_test, y_test)))

"""

*   Decision Tree
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

dt_model = DecisionTreeRegressor(max_depth=10, random_state=42)

dt_model.fit(X_train, y_train)

"""
*   Evaluation of Decision Tree Regressor



"""

# Predict the target variable for test data
y_pred_dt = dt_model.predict(X_test)

mae_dt = mean_absolute_error(y_test, y_pred_dt)
mse_dt = mean_squared_error(y_test, y_pred_dt)
rmse_dt = mse_dt ** 0.5
r2_dt = r2_score(y_test, y_pred_dt)

print(f"Decision Tree MAE: {mae_dt:.2f}")
print(f"Decision Tree MSE: {mse_dt:.2f}")
print(f"Decision Tree RMSE: {rmse_dt:.2f}")
print(f"Decision Tree R²: {r2_dt:.2f}")

print("Test set score: {:.2f}".format(dt_model.score(X_test, y_test)))

"""*   Neural Network




"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

import numpy as np

print("NaNs in X_train_scaled:", np.isnan(X_train_scaled).sum())
print("Infs in X_train_scaled:", np.isinf(X_train_scaled).sum())

X_train_scaled = np.nan_to_num(X_train_scaled)
X_test_scaled = np.nan_to_num(X_test_scaled)

print("X_train_scaled Mean:", X_train_scaled.mean(axis=0))
print("X_train_scaled Std Dev:", X_train_scaled.std(axis=0))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define the neural network
nn_model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1)
])

# Compile the model
nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = nn_model.fit(X_train_scaled, y_train,
                       validation_split=0.2,
                       epochs=50,
                       batch_size=32,
                       verbose=1)

"""

*   Evaluation of Neural Network


"""

# Evaluate on test data
test_loss, test_mae = nn_model.evaluate(X_test_scaled, y_test)

print(f"Test Loss (MSE): {test_loss:.2f}")
print(f"Test MAE: {test_mae:.2f}")

y_pred_nn = nn_model.predict(X_test_scaled)

# Example: Compare first 10 predictions with actual values
print("Actual vs. Predicted Selling Prices:")
for actual, predicted in zip(y_test[:10], y_pred_nn[:10]):
    print(f"Actual: {actual}, Predicted: {predicted[0]:.2f}")

y_pred_nn = nn_model.predict(X_test_scaled).flatten()

mae_nn = mean_absolute_error(y_test, y_pred_nn)
mse_nn = mean_squared_error(y_test, y_pred_nn)
rmse_nn = mse_nn ** 0.5
r2_nn = r2_score(y_test, y_pred_nn)

print(f"Neural Network MAE: {mae_nn:.2f}")
print(f"Neural Network MSE: {mse_nn:.2f}")
print(f"Neural Network RMSE: {rmse_nn:.2f}")
print(f"Neural Network R²: {r2_nn:.2f}")

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

results = pd.DataFrame({
    "Model": ["Random Forest", "Decision Tree", "Neural Network"],
    "MAE": [mae_rf, mae_dt, mae_nn],
    "MSE": [mse_rf, mse_dt, mse_nn],
    "RMSE": [rmse_rf, rmse_dt, rmse_nn],
    "R²": [r2_rf, r2_dt, r2_nn]
})

print(results)

plt.figure(figsize=(12, 6))
plt.scatter(y_test, y_pred_rf, label="Random Forest", alpha=0.6)
plt.scatter(y_test, y_pred_dt, label="Decision Tree", alpha=0.6)
plt.scatter(y_test, y_pred_nn, label="Neural Network", alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs Predicted")
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(y_pred_rf, y_test - y_pred_rf, label="Random Forest", alpha=0.6)
plt.scatter(y_pred_dt, y_test - y_pred_dt, label="Decision Tree", alpha=0.6)
plt.scatter(y_pred_nn, y_test - y_pred_nn, label="Neural Network", alpha=0.6)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Model accuracies
models = ["Random Forest", "Decision Tree", "Neural Network"]
accuracies = [r2_rf*100, r2_dt*100, r2_nn*100]

# Plotting the bar chart
plt.figure(figsize=(10, 6))
plt.bar(models, accuracies, color=['blue', 'green', 'purple'], alpha=0.7)
plt.xlabel("Models", fontsize=12)
plt.ylabel("Accuracy (%)", fontsize=12)
plt.title("Model Accuracy Comparison", fontsize=14)
plt.ylim(80, 100)
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.2, f"{acc}%", ha='center', fontsize=10)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()